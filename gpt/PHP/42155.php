<?php\n\n// Array of feed URLs\n$feeds = [\n    'https://example.com/feed1.xml',\n    'https://example.com/feed2.xml',\n    // Add all other feed URLs here\n];\n\n// Function to fetch a single feed\nfunction fetchFeed($url) {\n    $ch = curl_init();\n    curl_setopt($ch, CURLOPT_URL, $url);\n    curl_setopt($ch, CURLOPT_RETURNTRANSFER, 1);\n    $data = curl_exec($ch);\n    curl_close($ch);\n    return $data;\n}\n\n// Fetch feeds in batches\nfunction fetchFeedsInBatches($feeds, $batchSize) {\n    $totalFeeds = count($feeds);\n    $batches = array_chunk($feeds, $batchSize);\n    \n    foreach ($batches as $batch) {\n        $multiCurl = curl_multi_init();\n        $curlHandles = [];\n        \n        // Initialize curl handles for each feed in the batch\n        foreach ($batch as $feedUrl) {\n            $ch = curl_init();\n            curl_setopt($ch, CURLOPT_URL, $feedUrl);\n            curl_setopt($ch, CURLOPT_RETURNTRANSFER, 1);\n            curl_multi_add_handle($multiCurl, $ch);\n            $curlHandles[] = $ch;\n        }\n        \n        // Execute all requests concurrently\n        $running = null;\n        do {\n            curl_multi_exec($multiCurl, $running);\n            curl_multi_select($multiCurl);\n        } while ($running > 0);\n        \n        // Process each response\n        foreach ($curlHandles as $ch) {\n            $data = curl_multi_getcontent($ch);\n            // Process the feed data here (e.g., store in database)\n            curl_multi_remove_handle($multiCurl, $ch);\n        }\n        \n        curl_multi_close($multiCurl);\n        \n        // Delay between batches\n        sleep(60); // Sleep for 1 minute\n    }\n}\n\n// Define batch size\n$batchSize = 5; // Number of feeds to fetch per batch\n\n// Fetch feeds\nfetchFeedsInBatches($feeds, $batchSize);\n\n?>