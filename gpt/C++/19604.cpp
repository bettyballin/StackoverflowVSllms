#include <cuda_runtime.h>\n#include <iostream>\n\n// CUDA kernel to add elements of two arrays\n__global__ void add(int n, float *x, float *y) {\n    int index = blockIdx.x * blockDim.x + threadIdx.x;\n    int stride = blockDim.x * gridDim.x;\n    for (int i = index; i < n; i += stride)\n        y[i] = x[i] + y[i];\n}\n\nint main() {\n    int N = 1<<20; // 1M elements\n    float *x, *y;\n\n    // Allocate Unified Memory â€“ accessible from CPU or GPU\n    cudaMallocManaged(&x, N * sizeof(float));\n    cudaMallocManaged(&y, N * sizeof(float));\n\n    // Initialize x and y arrays on the host\n    for (int i = 0; i < N; i++) {\n        x[i] = 1.0f;\n        y[i] = 2.0f;\n    }\n\n    // Run kernel on 1M elements on the GPU\n    int blockSize = 256;\n    int numBlocks = (N + blockSize - 1) / blockSize;\n    add<<<numBlocks, blockSize>>>(N, x, y);\n\n    // Wait for GPU to finish before accessing on host\n    cudaDeviceSynchronize();\n\n    // Check for errors (all values should be 3.0f)\n    for (int i = 0; i < N; i++) {\n        if (y[i] != 3.0f) {\n            std::cerr << "Error: y[" << i << "] = " << y[i] << " != 3.0f\n";\n            return -1;\n        }\n    }\n\n    // Free memory\n    cudaFree(x);\n    cudaFree(y);\n\n    std::cout << "Success!\n";\n    return 0;\n}