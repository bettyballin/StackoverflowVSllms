import os\nimport hashlib\nfrom PIL import Image\nimport imagehash\n\ndef compute_full_file_hash(file_path):\n    hash_algo = hashlib.sha256()\n    with open(file_path, 'rb') as f:\n        while chunk := f.read(8192):\n            hash_algo.update(chunk)\n    return hash_algo.hexdigest()\n\ndef compute_perceptual_hash(file_path):\n    with Image.open(file_path) as img:\n        return str(imagehash.phash(img))\n\ndef find_duplicate_images(directory):\n    file_hashes = {}\n    perceptual_hashes = {}\n    \n    for root, _, files in os.walk(directory):\n        for file in files:\n            file_path = os.path.join(root, file)\n            try:\n                file_hash = compute_full_file_hash(file_path)\n                perceptual_hash = compute_perceptual_hash(file_path)\n                \n                if file_hash in file_hashes:\n                    print(f"Duplicate found by file hash: {file_path} and {file_hashes[file_hash]}")\n                else:\n                    file_hashes[file_hash] = file_path\n                \n                if perceptual_hash in perceptual_hashes:\n                    print(f"Duplicate found by perceptual hash: {file_path} and {perceptual_hashes[perceptual_hash]}")\n                else:\n                    perceptual_hashes[perceptual_hash] = file_path\n            except Exception as e:\n                print(f"Error processing file {file_path}: {e}")\n\n# Example usage\nfind_duplicate_images('/path/to/image/directory')