from selenium import webdriver\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.common.keys import Keys\nimport time\nfrom bs4 import BeautifulSoup\n\n# Configure the webdriver (Make sure you have the appropriate driver installed, e.g., chromedriver)\ndriver = webdriver.Chrome()\n\n# Open the search page\ndriver.get("http://pubs.acs.org/search/advanced")\n\n# Assume you have a list of articles with authors, titles, etc.\narticles = [\n    {\n        "author": "Author Name",\n        "title": "Article Title",\n        "volume": "Volume Number",\n    },\n    # Add more articles as needed\n]\n\nresults = []\n\nfor article in articles:\n    # Find the input fields and enter the data\n    author_input = driver.find_element(By.NAME, "author")\n    author_input.clear()\n    author_input.send_keys(article["author"])\n\n    title_input = driver.find_element(By.NAME, "title")\n    title_input.clear()\n    title_input.send_keys(article["title"])\n\n    volume_input = driver.find_element(By.NAME, "volume")\n    volume_input.clear()\n    volume_input.send_keys(article["volume"])\n\n    # Submit the form\n    title_input.send_keys(Keys.RETURN)\n    \n    # Wait for the results page to load\n    time.sleep(5)  # Adjust this time as needed\n\n    # Parse the results page\n    soup = BeautifulSoup(driver.page_source, 'html.parser')\n\n    # Extract DOI (adjust the selector according to the page structure)\n    doi_element = soup.find('a', {'class': 'doi'})\n    if doi_element:\n        doi = doi_element.text.strip()\n        results.append({"article": article, "doi": doi})\n\n# Close the browser\ndriver.quit()\n\n# Print the results\nfor result in results:\n    print(f"Article: {result['article']}")\n    print(f"DOI: {result['doi']}")\n    print("")\n\n# You can also save the results to a file or database as needed