from airflow import DAG\n    from airflow.operators.bash_operator import BashOperator\n    from datetime import datetime\n\n    default_args = {\n        'owner': 'airflow',\n        'start_date': datetime(2023, 1, 1),\n    }\n\n    dag = DAG('data_pipeline', default_args=default_args, schedule_interval='@daily')\n\n    t1 = BashOperator(\n        task_id='process_data',\n        bash_command='python process_data.py data.csv processed_data.csv',\n        dag=dag)\n\n    t2 = BashOperator(\n        task_id='compute_results',\n        bash_command='python compute_results.py processed_data.csv result.csv',\n        dag=dag)\n\n    t1 >> t2