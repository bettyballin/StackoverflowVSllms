import os\nfrom bs4 import BeautifulSoup\n\ndef extract_links_from_html(file_path):\n    with open(file_path, 'r', encoding='utf-8') as file:\n        soup = BeautifulSoup(file, 'html.parser')\n        links = [a['href'] for a in soup.find_all('a', href=True)]\n    return links\n\ndef main():\n    html_directory = 'path_to_html_files_directory'\n    all_links = {}\n\n    for root, dirs, files in os.walk(html_directory):\n        for file in files:\n            if file.endswith('.html'):\n                file_path = os.path.join(root, file)\n                links = extract_links_from_html(file_path)\n                all_links[file_path] = links\n\n    # Print or save the link structure as needed\n    for page, links in all_links.items():\n        print(f"Page: {page}")\n        for link in links:\n            print(f"  Link: {link}")\n\nif __name__ == "__main__":\n    main()