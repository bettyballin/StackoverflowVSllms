import numpy as np\n\n# Example word frequency data (normalized)\nbnc_freq = {"the": 0.9, "book": 0.6, "zyzzyva": 0.1}\nwordnet_freq = {"the": 0.85, "book": 0.65, "zyzzyva": 0.05}\ninternal_freq = {"the": 0.95, "book": 0.7, "zyzzyva": 0.2}\n\n# Weights for each source\nweights = {"bnc": 0.4, "wordnet": 0.3, "internal": 0.3}\n\n# List of words to classify\nwords = ["the", "book", "zyzzyva"]\n\n# Function to calculate the weighted score\ndef calculate_weighted_score(word):\n    bnc_score = bnc_freq.get(word, 0)\n    wordnet_score = wordnet_freq.get(word, 0)\n    internal_score = internal_freq.get(word, 0)\n    \n    weighted_score = (weights["bnc"] * bnc_score +\n                      weights["wordnet"] * wordnet_score +\n                      weights["internal"] * internal_score)\n    return weighted_score\n\n# Classify words\nthreshold = 0.5  # Example threshold for common/rare classification\nclassification = {}\n\nfor word in words:\n    score = calculate_weighted_score(word)\n    classification[word] = "common" if score >= threshold else "rare"\n\n# Print classification results\nfor word, cls in classification.items():\n    print(f"Word: {word}, Classification: {cls}")\n\n# Output:\n# Word: the, Classification: common\n# Word: book, Classification: common\n# Word: zyzzyva, Classification: rare