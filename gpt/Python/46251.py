import pyodbc\nimport logging\n\n# Configure logging\nlogging.basicConfig(filename='update_log.txt', level=logging.INFO, format='%(asctime)s:%(levelname)s:%(message)s')\n\n# Connect to the database\nconn = pyodbc.connect('DRIVER={SQL Server};SERVER=server_name;DATABASE=MyDatabase;UID=user;PWD=password')\ncursor = conn.cursor()\n\ntry:\n    # Backup the database\n    cursor.execute("BACKUP DATABASE MyDatabase TO DISK = 'C:\\Backup\\MyDatabase.bak'")\n    conn.commit()\n    logging.info('Database backup completed.')\n    \n    # Detect duplicates\n    cursor.execute("SELECT ColumnA, COUNT(*) FROM MyTable GROUP BY ColumnA HAVING COUNT(*) > 1")\n    duplicates = cursor.fetchall()\n    \n    if duplicates:\n        # Archive duplicates\n        cursor.execute("""\n            INSERT INTO MyTable_Archive (ColumnA, ColumnB, ColumnC)\n            SELECT ColumnA, ColumnB, ColumnC\n            FROM MyTable t\n            WHERE EXISTS (\n                SELECT 1 FROM MyTable\n                WHERE ColumnA = t.ColumnA\n                GROUP BY ColumnA\n                HAVING COUNT(*) > 1\n            )\n        """)\n        conn.commit()\n        logging.info('Archived duplicates.')\n        \n        # Remove duplicates from the original table\n        cursor.execute("""\n            DELETE FROM MyTable\n            WHERE ColumnA IN (\n                SELECT ColumnA\n                FROM MyTable\n                GROUP BY ColumnA\n                HAVING COUNT(*) > 1\n            )\n        """)\n        conn.commit()\n        logging.info('Removed duplicates from MyTable.')\n\n    # Add unique index\n    cursor.execute("CREATE UNIQUE INDEX idx_unique_ColumnA ON MyTable (ColumnA)")\n    conn.commit()\n    logging.info('Unique index added to MyTable.')\n    \nexcept Exception as e:\n    logging.error(f'Error during database update: {e}')\n    conn.rollback()\nfinally:\n    conn.close()\n    logging.info('Database connection closed.')