from transformers import BertTokenizer, BertModel\nimport torch\n\n# Load pre-trained BERT model and tokenizer\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nmodel = BertModel.from_pretrained('bert-base-uncased')\n\n# Tokenize and convert to tensor\ntokens = tokenizer(products, padding=True, truncation=True, return_tensors='pt')\n\n# Get BERT embeddings\nwith torch.no_grad():\n    outputs = model(**tokens)\n    embeddings = outputs.last_hidden_state.mean(dim=1)\n\n# Perform clustering on BERT embeddings\nkmeans = KMeans(n_clusters=3, random_state=42)\nkmeans.fit(embeddings)\n\n# Assign products to clusters\nclusters = kmeans.predict(embeddings)\n\n# Create a DataFrame to view the results\nproduct_clusters = pd.DataFrame({'Product': products, 'Cluster': clusters})\nprint(product_clusters)