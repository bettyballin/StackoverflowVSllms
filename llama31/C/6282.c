// Example: Cache-aware matrix multiplication\n\n#define MATRIX_SIZE 1000\n#define CACHE_LINE_SIZE 64\n\nvoid matmul(float *A, float *B, float *C) {\n    int i, j, k;\n    int block_size = CACHE_LINE_SIZE / sizeof(float);\n\n    for (i = 0; i < MATRIX_SIZE; i += block_size) {\n        for (j = 0; j < MATRIX_SIZE; j += block_size) {\n            for (k = 0; k < MATRIX_SIZE; k += block_size) {\n                // Prefetch data into cache\n                __builtin_prefetch(&A[i * MATRIX_SIZE + k]);\n                __builtin_prefetch(&B[k * MATRIX_SIZE + j]);\n\n                // Perform block-wise matrix multiplication\n                for (int x = 0; x < block_size; x++) {\n                    for (int y = 0; y < block_size; y++) {\n                        C[i * MATRIX_SIZE + j + x * MATRIX_SIZE + y] += \n                            A[i * MATRIX_SIZE + k + x] * B[k * MATRIX_SIZE + j + y];\n                    }\n                }\n            }\n        }\n    }\n}