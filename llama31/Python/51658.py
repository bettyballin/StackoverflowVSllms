import nltk\nfrom nltk.tokenize import word_tokenize\nfrom spacy import displacy\n\n# Load language models\nnlp_en = spacy.load("en_core_web_sm")\nnlp_ru = spacy.load("ru_core_news_sm")\nnlp_he = spacy.load("he_core_news_sm")\n\ndef normalize_text(text):\n    # Tokenize text\n    tokens = word_tokenize(text)\n    \n    # Normalize tokens\n    normalized_tokens = []\n    for token in tokens:\n        # Handle spelling mistakes\n        if token in ["fourty", "forty"]:\n            normalized_tokens.append("40")\n        # Handle ordinal numbers\n        elif token.endswith("st") or token.endswith("nd") or token.endswith("rd"):\n            normalized_tokens.append(token[:-2])\n        # Handle fractions\n        elif token == "one third":\n            normalized_tokens.append("1/3")\n        # ...\n        else:\n            normalized_tokens.append(token)\n    \n    # Join normalized tokens\n    normalized_text = " ".join(normalized_tokens)\n    \n    return normalized_text\n\ndef parse_text(text):\n    # Detect language\n    lang = detect_language(text)\n    \n    # Load language model\n    if lang == "en":\n        nlp = nlp_en\n    elif lang == "ru":\n        nlp = nlp_ru\n    elif lang == "he":\n        nlp = nlp_he\n    \n    # Parse text\n    doc = nlp(text)\n    \n    # Extract entities\n    entities = [(ent.text, ent.label_) for ent in doc.ents]\n    \n    # Handle entities\n    for entity in entities:\n        # Handle numbers\n        if entity[1] == "CARDINAL":\n            # Convert to numeric value\n            value = convert_to_numeric(entity[0])\n            # ...\n        # Handle dates\n        elif entity[1] == "DATE":\n            # Convert to standard format\n            date = convert_to_standard_date(entity[0])\n            # ...\n    \n    # ...