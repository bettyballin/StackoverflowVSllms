import requests\nfrom bs4 import BeautifulSoup\nimport concurrent.futures\n\ndef fetch_and_extract(url, filename):\n    response = requests.get(url)\n    soup = BeautifulSoup(response.text, 'html.parser')\n    text = soup.get_text()\n    with open(filename, 'w', encoding='utf-8') as file:\n        file.write(text)\n\ndef main(urls_filenames):\n    with concurrent.futures.ThreadPoolExecutor() as executor:\n        executor.map(lambda pair: fetch_and_extract(*pair), urls_filenames)\n\nif __name__ == "__main__":\n    urls = ['http://example.com/page1', 'http://example.com/page2']\n    filenames = ['page1.txt', 'page2.txt']\n    main(zip(urls, filenames))