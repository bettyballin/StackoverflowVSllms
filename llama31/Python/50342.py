import os\nfrom bs4 import BeautifulSoup\nfrom whoosh.index import create_in\nfrom whoosh.fields import *\nfrom whoosh.writing import AsyncWriter\n\n# Define the schema for the search index\nschema = Schema(title=TEXT(stored=True), path=ID(stored=True), content=TEXT)\n\n# Create the index directory if it doesn't exist\nif not os.path.exists("indexdir"):\n    os.mkdir("indexdir")\n    ix = create_in("indexdir", schema)\nelse:\n    ix = open_dir("indexdir")\n\n# Function to extract main content and index it\ndef index_page(url, title, content_area_selector):\n    # Assuming you have a way to fetch the page content (e.g., requests.get)\n    # For simplicity, let's assume the content is already fetched and parsed\n    soup = BeautifulSoup(content, 'html.parser')\n    \n    # Extract main content area\n    main_content = soup.select_one(content_area_selector).text.strip()\n    \n    # Write to index\n    writer = AsyncWriter(ix)\n    writer.add_document(title=title, path=url, content=main_content)\n    writer.commit()\n\n# Example usage\n# Fetch your pages, and for each page call something like:\n# (Make sure to implement the fetching logic and define the correct selector for your main content area)\n# index_page("https://example.com/page1", "Page 1 Title", "#mainContentArea")\n\n# After indexing all pages, you can search like this:\nfrom whoosh.qparser import QueryParser\n\nqp = QueryParser("content", schema=ix.schema)\nq = qp.parse("New York")\n\nwith ix.searcher() as s:\n    results = s.search(q)\n    for result in results:\n        print(result["title"], result["path"])