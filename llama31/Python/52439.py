import hashlib\n\ndef find_common_blocks(f1, f2, min_length=2):\n    # Read files\n    with open(f1, 'rb') as file1, open(f2, 'rb') as file2:\n        data1 = file1.read()\n        data2 = file2.read()\n\n    # Calculate hashes\n    hashes1 = {}\n    for i in range(len(data1) - min_length + 1):\n        chunk = data1[i:i + min_length]\n        hash = hashlib.md5(chunk).hexdigest()\n        if hash not in hashes1:\n            hashes1[hash] = [(i, chunk)]\n        else:\n            hashes1[hash].append((i, chunk))\n\n    # Find common blocks\n    common_blocks = []\n    for i in range(len(data2) - min_length + 1):\n        chunk = data2[i:i + min_length]\n        hash = hashlib.md5(chunk).hexdigest()\n        if hash in hashes1:\n            for offset, _ in hashes1[hash]:\n                # Verify the match\n                match_len = min_length\n                while (i + match_len <= len(data2) and\n                       offset + match_len <= len(data1) and\n                       data2[i:i + match_len] == data1[offset:offset + match_len]):\n                    match_len += 1\n                common_blocks.append((match_len - 1, offset, i))\n\n    # Filter and print common blocks\n    filtered_blocks = [(length, f1_offset, f2_offset) for length, f1_offset, f2_offset in common_blocks if length >= min_length]\n    for length, f1_offset, f2_offset in filtered_blocks:\n        print(f"length {length}: {data1[f1_offset:f1_offset + length]} in f1@{f1_offset} and f2@{f2_offset}")\n\n# Usage\nfind_common_blocks('f1.txt', 'f2.txt')