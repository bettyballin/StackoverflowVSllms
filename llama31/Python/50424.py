import collections\nimport re\n\n# Define the list of words you're interested in\ntarget_words = ["word1", "word2", "word3"]  # replace with your own list\n\n# Open the output file\nwith open("output.tsv", "w") as outf:\n    # Iterate over the input files\n    for file in glob.glob("*.txt"):  # replace with your own file pattern\n        # Open the input file\n        with open(file, "r") as inf:\n            # Read the file contents\n            text = inf.read()\n            # Convert to lowercase and split into words\n            words = re.findall(r"\b\w+\b", text.lower())\n            # Count the frequency of target words\n            freq = collections.Counter(word for word in words if word in target_words)\n            # Write the frequency counts to the output file\n            outf.write(f"{file}\t" + "\t".join(f"{word}:{freq[word]}" for word in target_words) + "\n")