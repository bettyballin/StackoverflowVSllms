import re\n\ndef preprocess_text(text):\n    # Remove existing hard-wrap newlines\n    text = re.sub(r'(?<=[^\n])\n(?=[^\n])', ' ', text)\n    return text\n\ndef tokenize_text(text):\n    # Split text into individual tokens\n    tokens = re.split(r'(\s+|[^\w\s])', text)\n    return tokens\n\ndef classify_newlines(tokens):\n    # Classify each newline character\n    newlines = []\n    for i, token in enumerate(tokens):\n        if token == '\n':\n            if i > 0 and tokens[i-1] in ['.', '?', '!']:\n                newlines.append((token, 'end-of-paragraph'))\n            elif i > 0 and tokens[i-1].isspace():\n                newlines.append((token, 'hard-wrap'))\n            else:\n                newlines.append((token, 'semantic'))\n    return newlines\n\ndef rewrap_text(tokens, newlines, max_width=79):\n    # Re-wrap the text\n    wrapped_text = ''\n    current_line = ''\n    for token in tokens:\n        if token == '\n':\n            wrapped_text += '\n'\n            current_line = ''\n        else:\n            current_line += token\n            if len(current_line) > max_width:\n                wrapped_text += '\n'\n                current_line = ''\n    wrapped_text += current_line\n    return wrapped_text\n\n# Example usage\ntext = 'Oops, I entered my address incorrectly. Can you change it to\n\nFred Smith 123 Main St Anytown, VA 12345\n\nThanks!\n\n-- Fred Smith Contoso Product Lover'\ntext = preprocess_text(text)\ntokens = tokenize_text(text)\nnewlines = classify_newlines(tokens)\nwrapped_text = rewrap_text(tokens, newlines)\nprint(wrapped_text)