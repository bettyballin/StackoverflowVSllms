from bs4 import BeautifulSoup, NavigableString\nimport requests\n\ndef extract_content(url):\n    """\n    Extract meaningful content from an HTML page.\n    \n    :param url: URL of the HTML page to parse.\n    :return: Extracted content as text.\n    """\n    response = requests.get(url)\n    soup = BeautifulSoup(response.text, 'html.parser')\n    \n    # Find all text elements\n    text_elements = []\n    for element in soup.descendants:\n        if isinstance(element, NavigableString) and element.strip():\n            # Heuristic: Collect text content if it's more than 100 characters\n            if len(element.strip()) > 100:\n                text_elements.append(str(element))\n    \n    # Optionally, you could collect P and DIV elements with significant text content\n    content_elements = soup.select('p, div')\n    for element in content_elements:\n        text = element.get_text(strip=True)\n        if len(text) > 100:\n            text_elements.append(text)\n    \n    # Join collected text elements\n    content = '\n\n'.join(text_elements)\n    \n    return content\n\n# Example usage\nurl = "https://example.com"\nprint(extract_content(url))