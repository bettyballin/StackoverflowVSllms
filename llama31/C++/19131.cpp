#include <iostream>\n#include <string>\n#include <unordered_map>\n\nclass Tokenizer {\npublic:\n    void addRule(const std::string& pattern, const std::string& token) {\n        rules_[pattern] = token;\n    }\n\n    std::string tokenize(const std::string& input) {\n        std::string output;\n        size_t pos = 0;\n        while (pos < input.size()) {\n            size_t maxMatchLen = 0;\n            std::string maxMatchToken;\n            for (const auto& rule : rules_) {\n                const std::string& pattern = rule.first;\n                if (input.substr(pos, pattern.size()) == pattern && pattern.size() > maxMatchLen) {\n                    maxMatchLen = pattern.size();\n                    maxMatchToken = rule.second;\n                }\n            }\n            if (!maxMatchToken.empty()) {\n                output += maxMatchToken + " ";\n                pos += maxMatchLen;\n            } else {\n                // Handle the case where no rule matches\n                output += input[pos];\n                pos++;\n            }\n        }\n        return output;\n    }\n\nprivate:\n    std::unordered_map<std::string, std::string> rules_;\n};\n\nint main() {\n    Tokenizer tokenizer;\n    tokenizer.addRule("a", "V-A");\n    tokenizer.addRule("p", "C-PA");\n    tokenizer.addRule("pp", "C-PPA");\n    tokenizer.addRule("u", "V-U");\n\n    std::string input = "appu";\n    std::cout << tokenizer.tokenize(input) << std::endl;\n\n    return 0;\n}