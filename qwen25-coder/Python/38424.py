import requests\nfrom bs4 import BeautifulSoup\n\ndef check_url(url):\n    try:\n        response = requests.head(url, allow_redirects=True)\n        if response.status_code == 200:\n            return True\n        else:\n            return False\n    except requests.ConnectionError:\n        return False\n\ndef find_broken_links(base_url):\n    page_response = requests.get(base_url)\n    soup = BeautifulSoup(page_response.content, 'html.parser')\n    broken_links = []\n\n    for link in set(soup.find_all('a', href=True)):\n        url = link['href']\n        if not (url.startswith('http://') or url.startswith('https://')):\n            url = f"{base_url}{url}"\n        if not check_url(url):\n            broken_links.append(url)\n\n    return broken_links\n\n# Usage\nbase_url = 'https://example.com'\nbroken_links = find_broken_links(base_url)\nprint("Broken links found:", broken_links)