import os\n\n# Define the path to the directory containing your text files and the terms list file\ntext_directory = 'texts/'\nterms_file = 'terms.txt'\noutput_file = 'word_frequencies.csv'\n\n# Read the terms into a set for fast lookup\nwith open(terms_file, 'r') as f:\n    terms = {line.strip().lower() for line in f}\n\n# Initialize a dictionary to store term counts for each file\nterm_counts_per_file = {}\n\n# Process each text file\nfor filename in os.listdir(text_directory):\n    if filename.endswith('.txt'):\n        filepath = os.path.join(text_directory, filename)\n        with open(filepath, 'r', encoding='utf-8') as f:\n            # Read all words and convert to lowercase for case-insensitive comparison\n            words = f.read().split()\n            words = [word.lower() for word in words]\n            \n            # Count occurrences of each term in the predefined list\n            term_counts = {term: 0 for term in terms}\n            for word in words:\n                if word in terms:\n                    term_counts[word] += 1\n            \n            term_counts_per_file[filename] = term_counts\n\n# Write the frequency data to a CSV file\nwith open(output_file, 'w') as f:\n    # Write header row\n    header = list(terms)\n    f.write('Filename,' + ','.join(header) + '\n')\n    \n    # Write counts for each file\n    for filename, term_counts in term_counts_per_file.items():\n        row = [filename] + [str(term_counts[term]) for term in header]\n        f.write(','.join(row) + '\n')