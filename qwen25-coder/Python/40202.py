import scrapy\nfrom urllib.parse import urljoin\n\nclass FormCheckerSpider(scrapy.Spider):\n    name = 'form_checker'\n    start_urls = ['file:///path/to/your/courseware/directory/index.html']  # Replace with your starting page URL or file path\n\n    def parse(self, response):\n        for form in response.css('form'):\n            action_url = urljoin(response.url, form.attrib.get('action', '#'))\n            method = form.attrib.get('method', 'get').lower()\n\n            if '#' in action_url:\n                self.logger.warning(f'Form with broken or incomplete action URL: {action_url} on page {response.url}')\n            elif method == 'post':\n                # Handle POST forms differently, possibly send a sample POST request\n                yield {'form': form, 'url': response.url, 'method': method, 'status': 'POST handling required'}\n            else:\n                yield scrapy.Request(action_url, callback=self.check_link_status,\n                                       cb_kwargs={'original_form_url': action_url, 'source_page': response.url})\n\n    def check_link_status(self, response, original_form_url, source_page):\n        if response.status == 404:\n            self.logger.error(f'Form action URL {original_form_url} from page {source_page} returned a 404 error')