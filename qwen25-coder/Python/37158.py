import requests\nfrom bs4 import BeautifulSoup\nimport os\nimport shutil\n\ndef download_page(url, folder_name):\n    if not os.path.exists(folder_name):\n        os.makedirs(folder_name)\n\n    response = requests.get(url)\n    soup = BeautifulSoup(response.text, 'html.parser')\n\n    # Save the HTML content\n    html_path = os.path.join(folder_name, 'index.html')\n    with open(html_path, 'w', encoding='utf-8') as file:\n        file.write(str(soup))\n\n    # Modify links in the HTML\n    for link in soup.find_all('a'):\n        if 'href' in link.attrs:\n            href = link['href']\n            # Assuming relative URLs need changing, others remain as is.\n            if not href.startswith(('http://', 'https://')):\n                link['href'] = os.path.relpath(os.path.join(folder_name, href), folder_name)\n\n    # Save the modified HTML content\n    with open(html_path, 'w', encoding='utf-8') as file:\n        file.write(str(soup))\n\n# Usage\ndownload_page('http://example.com', 'downloaded_site')