class TrieNode:\n    def __init__(self):\n        self.children = {}\n        self.frequency = 0\n\nclass Trie:\n    def __init__(self):\n        self.root = TrieNode()\n\n    def insert(self, word):\n        node = self.root\n        for char in word:\n            if char not in node.children:\n                node.children[char] = TrieNode()\n            node = node.children[char]\n        node.frequency += 1\n\ndef find_high_frequency_words(file_path):\n    trie = Trie()\n    with open(file_path, 'r') as file:\n        for line in file:\n            # Simple word splitting, you might need more sophisticated tokenization\n            words = line.strip().split()\n            for word in words:\n                # Optional: Normalize words (e.g., to lower case)\n                trie.insert(word.lower())\n\n    # Collect the highest frequency words\n    max_frequency = 0\n    high_frequency_words = []\n    def dfs(node, prefix):\n        nonlocal max_frequency, high_frequency_words\n        if node.frequency > max_frequency:\n            max_frequency = node.frequency\n            high_frequency_words = [prefix]\n        elif node.frequency == max_frequency and prefix:\n            high_frequency_words.append(prefix)\n        \n        for char, child_node in node.children.items():\n            dfs(child_node, prefix + char)\n\n    dfs(trie.root, "")\n    return high_frequency_words\n\n# Usage example\nfile_path = 'path/to/book.txt'\nhigh_frequencies = find_high_frequency_words(file_path)\nprint("High frequency words:", high_frequencies)