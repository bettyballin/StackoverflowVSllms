# Example Apache Airflow DAG in Python\n   from airflow import DAG\n   from airflow.operators.bash_operator import BashOperator\n   from datetime import datetime\n\n   default_args = {\n       'owner': 'airflow',\n       'start_date': datetime(2023, 1, 1),\n   }\n\n   dag = DAG('example_data_pipeline', schedule_interval='@daily', default_args=default_args)\n\n   process_data_task = BashOperator(\n       task_id='process_data',\n       bash_command='/path/to/process.py --input source_data.csv --output processed_data.csv',\n       dag=dag,\n   )\n\n   additional_processing_task = BashOperator(\n       task_id='additional_processing',\n       bash_command='/path/to/additional_processing.py --input processed_data.csv --output final_output.csv',\n       dag=dag,\n   )\n\n   process_data_task >> additional_processing_task