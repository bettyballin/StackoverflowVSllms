import timeit\nimport numpy as np\nfrom scipy.optimize import curve_fit\n\ndef analyze_function_time(f, input_sizes):\n    times = []\n    for size in input_sizes:\n        data = list(range(size))\n        elapsed_time = timeit.timeit(lambda: f(data), number=1)\n        times.append(elapsed_time)\n\n    # Define common complexity functions\n    def constant(n, a): return np.full_like(n, a)\n    def logn(n, a, b): return a * np.log2(n) + b\n    def linear(n, a, b): return a * n + b\n    def nlogn(n, a, b): return a * n * np.log2(n) + b\n    def quadratic(n, a, b): return a * (n ** 2) + b\n\n    complexities = {\n        "O(1)": constant,\n        "O(log n)": logn,\n        "O(n)": linear,\n        "O(n log n)": nlogn,\n        "O(n^2)": quadratic\n    }\n\n    best_fit = None\n    best_score = float('inf')\n\n    for name, func in complexities.items():\n        try:\n            popt, pcov = curve_fit(func, input_sizes, times)\n            residuals = times - func(input_sizes, *popt)\n            ss_res = np.sum(residuals ** 2)\n            ss_tot = np.sum((times - np.mean(times)) ** 2)\n            r_squared = 1 - (ss_res / ss_tot)\n\n            if r_squared < best_score:\n                best_fit = name\n                best_score = r_squared\n        except Exception as e:\n            continue\n\n    return best_fit, best_score\n\n# Example usage with a function assumed to be linear\ndef example_function(data):\n    for item in data:\n        # some operations on item\n        pass\n\ninput_sizes = [100, 200, 500, 1000, 2000]\ncomplexity, score = analyze_function_time(example_function, input_sizes)\nprint(f"Estimated complexity: {complexity}, R squared: {score}")