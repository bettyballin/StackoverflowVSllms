import hashlib\n\ndef hash_file(filepath):\n    hasher = hashlib.sha256()\n    with open(filepath, 'rb') as f:\n        # Read and update hash in chunks of 4K\n        for chunk in iter(lambda: f.read(4096), b""):\n            hasher.update(chunk)\n    return hasher.hexdigest()\n\ndef check_identical_files(filepaths):\n    first_hash = None\n    for filepath in filepaths:\n        current_hash = hash_file(filepath)\n        if first_hash is None:\n            first_hash = current_hash\n        elif first_hash != current_hash:\n            print(f"File {filepath} differs.")\n            return False\n    print("All files are identical.")\n    return True\n\n# Example usage for 1,000,000 files\nfile_paths = ['path/to/file{}'.format(i) for i in range(1000000)]\ncheck_identical_files(file_paths)