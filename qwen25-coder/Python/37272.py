def find_largest_cluster(highlight_positions, total_words, chunk_size=400):\n    highlight_indices = []\n    current_index = 0\n    \n    # Convert character positions to word indices (assuming words are separated by spaces)\n    # This part will vary based on your text structure and how you define a 'word'\n    for pos in highlight_positions:\n        while current_index < total_words and len(text[:pos].split()) > current_index:\n            current_index += 1\n        if current_index - 1 not in highlight_indices:\n            highlight_indices.append(current_index - 1)\n    \n    best_start = 0\n    max_count = 0\n    \n    # Sliding window to find the chunk with the most highlighted words\n    start, end = 0, 0\n    count = 0\n    \n    while end < total_words:\n        if highlight_indices and highlight_indices[0] < end:\n            count += 1\n            del highlight_indices[0]\n        \n        if (end - start) >= chunk_size:\n            if max_count < count:\n                best_start = start\n                max_count = count\n            \n            # Move the window\n            if highlight_indices and highlight_indices[0] == start:\n                count -= 1\n                del highlight_indices[0]\n            start += 1\n        \n        end += 1\n    \n    return best_start, min(best_start + chunk_size, total_words), max_count\n\n# Example usage:\nhighlight_positions = [25, 67, 89, 400, 500, 700]  # Character positions of highlighted words\ntotal_words = 1000  # Total number of words in the text\ntext = "Your large block of text goes here."  # Example text\n\nstart_word, end_word, max_highlighted = find_largest_cluster(highlight_positions, total_words)\nprint(f"Chunk starts at word index {start_word}, ends at {end_word} with {max_highlighted} highlighted words.")