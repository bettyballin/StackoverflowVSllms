import numpy as np\nfrom sklearn.ensemble import IsolationForest\nimport pandas as pd\n\n# Simulate the data readings (replace this with real data)\ndata = {'timestamp': pd.date_range(start='1/1/2023', periods=1000, freq='H'),\n        'free_space_gb': np.random.uniform(low=50.0, high=100.0, size=1000)}\ndf = pd.DataFrame(data)\n\n# Introduce some anomalies\nanomalies_indexes = np.random.choice(df.index, 20)\ndf.loc[anomalies_indexes, 'free_space_gb'] -= np.random.uniform(low=50.0, high=80.0, size=20)\n\n# Use Exponentially Weighted Moving Average (EWMA) to smooth the data and reduce noise\nalpha = 0.1  # Smoothing factor\ndf['ewma_free_space_gb'] = df['free_space_gb'].ewm(alpha=alpha, adjust=False).mean()\n\n# Fit an Isolation Forest model\nmodel = IsolationForest(contamination=0.05, random_state=42)\ndf['anomaly_score'] = model.fit_predict(df[['ewma_free_space_gb']])\ndf['is_anomaly'] = df['anomaly_score'].map({1: 0, -1: 1})\n\n# Filter out anomalies\nanomalies = df[df['is_anomaly'] == 1]\nprint(anomalies[['timestamp', 'free_space_gb', 'ewma_free_space_gb', 'anomaly_score', 'is_anomaly']])