import numpy as np\nfrom gensim.models import KeyedVectors\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# Load pre-trained Word2Vec model (binary format)\nmodel = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n\n# Sample documents\ndocuments = [\n    "Python is a great programming language",\n    "Java and Python are popular languages",\n    "I love machine learning in Python",\n    "Natural language processing uses libraries like spaCy"\n]\n\n# Function to average word vectors of a document\ndef avg_vector(text):\n    words = text.lower().split()\n    valid_words = [word for word in words if word in model]\n    vectors = [model[word] for word in valid_words]\n    return np.mean(vectors, axis=0) if vectors else np.zeros(model.vector_size)\n\n# Get average vectors for all documents\ndoc_vectors = [avg_vector(doc) for doc in documents]\n\n# Compute cosine similarity matrix\ncosine_sim_matrix = cosine_similarity(doc_vectors)\n\n# Function to get related articles\ndef get_related_articles(idx):\n    scores = list(enumerate(cosine_sim_matrix[idx]))\n    related_indices = sorted(scores, key=lambda x: x[1], reverse=True)[1:3]\n    return [(documents[i], score) for i, score in related_indices]\n\n# Example usage\nprint(get_related_articles(0))