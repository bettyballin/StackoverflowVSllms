from collections import Counter\nimport re\n\ndef generate_ngrams(text, n):\n    # Tokenize text into words\n    tokens = re.findall(r'\w+', text.lower())\n    # Generate n-grams from the tokens\n    return zip(*[tokens[i:] for i in range(n)])\n\ndef analyze_text(text, n=3):\n    # Generate and count n-grams\n    ngrams = generate_ngrams(text, n)\n    return Counter(ngrams)\n\n# Example usage\nmarkov_generated_text = "your markov generated text goes here"\nhuman_written_text = "your human written text goes here"\n\nmarkov_ngram_counts = analyze_text(markov_generated_text)\nhuman_ngram_counts = analyze_text(human_written_text)\n\nprint("Markov Generated Text N-Grams:", markov_ngram_counts.most_common(10))\nprint("Human Written Text N-Grams:", human_ngram_counts.most_common(10))\n\n# Compare the n-gram frequencies or other statistical features