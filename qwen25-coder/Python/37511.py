from bs4 import BeautifulSoup\nimport requests\nfrom readability import Document\n\ndef fetch_and_parse_blog(url):\n    response = requests.get(url)\n    if response.status_code != 200:\n        raise Exception(f"Failed to load page {url}")\n\n    # Use readability to parse the main content\n    doc = Document(response.text)\n    \n    # Optionally, use BeautifulSoup for further processing or validation\n    soup = BeautifulSoup(doc._c, "html.parser")\n    \n    # Extract and clean text\n    article = soup.find('article')\n    if not article:\n        # Fallback to finding div tags with class 'entry' or similar \n        possible_entries = soup.find_all(['div', 'section'], {'class': ['entry', 'post']})\n        articles = [p.get_text(strip=True) for p in possible_entries]\n        return '\n'.join(articles)\n    \n    return article.get_text(strip=True)\n\n# Example usage\nurl = "https://example-blog.com/post"\ntry:\n    text = fetch_and_parse_blog(url)\n    print(text[:500])  # Print first 500 characters of the extracted content\nexcept Exception as e:\n    print(f"An error occurred: {e}")