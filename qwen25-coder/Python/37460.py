def burrows_wheeler_transform(s):\n    """ Apply Burrows-Wheeler Transform """\n    table = sorted(s[i:] + s[:i] for i in range(len(s)))\n    last_column = [row[-1] for row in table]\n    return ''.join(last_column), table\n\ndef run_length_encoding(data):\n    """ Run-Length Encoding """\n    encoding = []\n    i = 0\n    while i < len(data):\n        count = 1\n        while i + 1 < len(data) and data[i] == data[i + 1]:\n            i += 1\n            count += 1\n        encoding.append((data[i], count))\n        i += 1\n    return encoding\n\ndef pack_words(words):\n    """ Pack words using Burrows-Wheeler Transform and Run-Length Encoding """\n    # Step 1: Create a single string with unique separators\n    sep = '\0'  # Use null character as separator; choose unique to the input\n    combined_string = sep.join(words) + sep\n    \n    # Step 2: Apply the Burrows-Wheeler Transform\n    bwt_result, _ = burrows_wheeler_transform(combined_string)\n    \n    # Step 3: Apply Run-Length Encoding\n    rle = run_length_encoding(bwt_result)\n    \n    # For the purpose of this example, let's just return the length and RLE\n    # to demonstrate how much we can compress.\n    packed_data = rle\n    \n    # To reconstruct words from BWT-RLE, you would need to implement inverse steps\n    # and track positions in the transformed data.\n    \n    return {\n        "rle": packed_data,\n        "length": len(bwt_result)\n    }\n\n# Example usage:\nwords = ["doll", "dollhouse", "house", "ragdoll"]\nresult = pack_words(words)\nprint(result)